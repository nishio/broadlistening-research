# NISHIOのコメント

## 手法の良さは3つに分割できる
意見集合をクラスタリングして可視化などする場合において、その手法の「良さ」は現状人間が見て非言語的に判断している。ここを定量化することによって、変更が改善であるかを人間の主観に頼らずに判断できるようにしたい。

良さは少なくとも3つの要素からなる:

- A: クラスタラベルの良さ
- B: ラベルがクラスタの中のデータをよく代表しているか
- C: ラベル同士の重複のなさ

---

1. 意見集合 $` S `$ を互いに素なクラスタ $` \{C_1, C_2, \dots, C_k\} `$ に分割し、
2. 各クラスタ $` C_i `$ に対して解説ラベル $` E_i `$ を付与する。

このとき、ラベルの「良さ」を以下の3要素で評価するとします。

- $` A(E_i) `$: ラベル $` E_i `$ 自体の質（説明としての適切さ）
- $` B(C_i, E_i) `$: ラスタ内のデータ $` C_i `$ をどれだけ代表しているか
- $` D(E_i, E_j) `$: 異なるクラスタのラベル $` E_i `$ と $` E_j `$ の類似度。重複が少ないほど良いとするため、ペナルティ項とする

## クラスタリング手法の比較実験

[notes/2024-02-10-02-クラスタリング手法比較.md](notes/2024-02-10-02-クラスタリング手法比較.md)の解説

![image](https://github.com/user-attachments/assets/18cb6eb6-7417-4817-9e98-c87254c4402e)

HDBSCANすると66クラスタ、k=66でk-meansやると、当然クラスタサイズはでかい。

平均クラスタサイズが一致するようにkを選ぶとk=1226、これならクラスタサイズは大体一致する。ただしHDBSCANの場合と違って最小クラスタサイズの指定がないので「1個だけ」とかがある(平均距離0付近のピーク)

---

<img width="878" alt="image" src="https://github.com/user-attachments/assets/b9f79545-91d4-461d-bd7a-1499503996b1" />

クラスタサイズが小さいこと起因の0付近を無視すると、k-meansでの平均距離はkがこんだけ違ってもあまり変わらず、HDBSCANははっきりと密集してる。これはおそらくkmeansが「薄い周辺」まで巻き込んでしまうことが原因

ただ、この図だとまだk-meansで「濃い方から66件取る」をやってないので、やると分布の端っこだけになってHDBSCANと同様になる可能性はある、それを描くべきだったね。

---

![image](https://github.com/user-attachments/assets/5897f80b-683d-4836-80de-926159f63bc5)

サイズ5以上でかつ濃い方から66件取ったもの(Dataset X)は、分布形状は違うけど、このメトリクスの範囲ではどちらがいいとは明瞭に言えない感じになった。

「濃い方を取らないk-means」は格段に広くて薄い、それはそう。

---

[notes/2024-02-11-01-クラスタリング手法比較更新.md](notes/2024-02-11-01-クラスタリング手法比較更新.md)の解説

UMAPで2次元にしてからのクラスタリング。

同じパラメータのHDBSCANで10倍近い個数のクラスタが抽出されている。

注目すべき点は、高次元だと95%くらいノイズとして捨てられていたのに、こちらでは半分も捨ててないというところ。
つまりこれが懸念してた「UMAPによって空間が歪むので密度ベースの手法HDBSCANなどが無意味になる可能性がある」という振る舞い。
クラスタが均質な密度になるように空間が歪められてしまっているので、ザラザラとした密度のばらつきだけでクラスタとみなして拾ってしまっている

ところでHDBSCANは「66個になるようなパラメータ」をどうやって決めていいかわからないので同じクラスタ数で比較するのが難しいね、クラスタ個数がやってみるまでわからないのは悪いところだなーと思った。
パラメータサーチで66個程度になるパラメータを見つけて、どうなるか実験するのはアリだけど、おそらく同じくらいのクラスタ密度になるようにk-meansをした後ランダムに選んだのとあまり変わらない結果になりそうだと思った。

## 今後の方向性

「クラスタラベルの良さ」の評価関数Aを定義することができれば、それぞれの手法やパラメータでどの程度「良い」のかを議論しやすくなる。

おそらくクラスタサイズが小さくなるだけでA()は上昇する。単純にk-meansでやると、クラスタ個数が増えることとのトレードオフになる。

なので密度などの指標で足切りして「良いクラスタだけに注目する」ということが必要になる。上記実験結果はUMAP後に密度で足切りをするのはランダムに選ぶのと大差ないのでは、という可能性を示唆している。

