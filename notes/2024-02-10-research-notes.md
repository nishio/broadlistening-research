# 研究ノート: 2024年2月10日

## 研究目的
クラスタリングアルゴリズムの比較実験を行い、密度ベースのクラスタリング（HDBSCAN）と距離ベースのクラスタリング（k-means）の特性の違いを明らかにする。特に、各クラスタの密度に着目して、両アルゴリズムの性能を評価する。

## データセットとリファレンス
1. aipubcomデータセット
   - 取得元: takahiroanno2024/anno-broadlistening リポジトリ
   - データの内容: 文化庁のAIと著作権に関する公開コメント（3,235件）
   - データファイル:
     * embeddings.pkl (261MB): コメントのベクトル表現
       - 注意: GitHubの容量制限（100MB）を超えるため、リポジトリには含めない
       - 取得方法: anno-broadelistening/scatter/pipeline/outputs/aipubcom/から取得
     * args.csv: コメントのメタデータ
     * その他の補助ファイル（clusters.csv, labels.csv等）

2. 参照実装
   - リポジトリ: nishio/ai_kj
   - 参照ファイル: dense_cluster_extruction.ipynb
   - 参照内容:
     * クラスタリングアルゴリズムの基本実装
     * HDBSCANのパラメータ設定の考え方
     * クラスタの評価指標の計算方法

## 今日の作業内容

### リポジトリのセットアップ
1. `broadlistening-research`リポジトリをクローン
   - 研究ノート用の新しいリポジトリとして設定
   - `notes`ディレクトリを作成して研究記録用に準備

2. データセット準備
   - `anno-broadlistening`リポジトリからaipubcomデータセットを取得開始
   - `dataset`ディレクトリを作成してデータ保存用に準備

### クラスタリング実験
1. 実験内容
   - HDBSCANとk-meansの比較
   - クラスタの密度と品質の評価
   - 同じクラスタ数での比較

2. 実験結果
   a) シルエット係数
      - HDBSCAN: 0.119
      - k-means: 0.088

   b) クラスタの特徴
      - HDBSCAN
        * 平均サイズ: 6.0
        * 平均密度: 1.267
        * 平均距離: 0.789
      - k-means
        * 平均サイズ: 69.0
        * 平均密度: 0.936
        * 平均距離: 1.073

3. 考察
   - HDBSCANは小さく密度の高いクラスタを形成
   - k-meansは大きく疎なクラスタを形成
   - HDBSCANの方が密度ベースの分析に適している

### 実装状況
- ブランチ名: `devin/1739154755-fix-experiment-structure`
- 作業ディレクトリ構造:
  - `/notes`: 研究ノート保存用
  - `/dataset/aipubcom`: データセット保存用
  - `/experiments`: 実験スクリプト保存用
    - `clustering_comparison.py`: クラスタリング実験の実装
    - `cluster_comparison.png`: 結果の可視化
    - `kmeans_cluster_metrics.csv`: k-meansの評価指標
    - `hdbscan_cluster_metrics.csv`: HDBSCANの評価指標

### 実験手順と結果の詳細
1. データの準備
   - embeddings.pkl（261MB）をdataset/aipubcomに配置
     * 注意：ファイルサイズがGitHubの制限（100MB）を超えるため、リポジトリには含めない
     * データ形状：(9883, 3072)
     * 個人および組織からのパブコメを含む
   - 実行時間の記録
     * HDBSCANクラスタリングは10分以上の実行時間が必要
     * メモリ使用量も記録（開始時：約1.6GB）

2. クラスタリングアルゴリズムの設定
   a) HDBSCAN（オリジナルのパラメータ）
      - min_cluster_size=5: クラスタの最小サイズ
      - max_cluster_size=30: クラスタの最大サイズ
      - min_samples=2: コアポイントの最小サンプル数
      - core_dist_n_jobs=-1: 並列処理を有効化（実行時間短縮のため）

   b) k-means
      - n_clusters=11: HDBSCANと同じクラスタ数を使用（初期実験）
      - random_state=42: 再現性のため固定
      - 大きなkでの実験（k=50,100,200）
        * k=50: 平均198ポイント/クラスタ
        * k=100: 平均99ポイント/クラスタ
        * k=200: 平均49ポイント/クラスタ
        * 実行時間: 0.1分
        * メモリ使用量: 1.6GB程度

3. 評価指標の計算
   - シルエット係数: クラスタの分離度と密度を評価
   - クラスタ内の平均距離: クラスタの密度を評価

## 本日の実験結果

1. HDBSCANクラスタリング（オリジナルパラメータ）
   - クラスタ数: 66
   - ノイズポイント: 9,351 (94.6%)
   - 実行時間: 7.0分
   - メモリ使用量: 1.6GB
   - 注: オリジナルの実装との違いは、データセットの拡張（組織からのパブコメ追加）が影響している可能性あり

2. k-meansクラスタリング（大きなk）
   - k=50: 平均198ポイント/クラスタ
   - k=100: 平均99ポイント/クラスタ
   - k=200: 平均49ポイント/クラスタ
   - 実行時間: 0.1分
   - メモリ使用量: 1.6GB
   - 特徴: クラスタサイズが均一に分布

3. UMAPとの組み合わせ実験（延期）
   - 次回以降の課題として検討

## 今後の課題
1. クラスタリング結果の質的評価
   - クラスタの密度指標の比較
   - クラスタ内の意味的一貫性の評価

2. パラメータ感度分析
   - HDBSCANパラメータの影響調査
   - k-meansのk値による結果の変化

3. 可視化と解釈
   - クラスタの特徴づけ
   - クラスタ間の関係性の分析

## 学んだこと
1. データセットの特性が重要
   - 組織からのパブコメ追加により、クラスタリング結果が変化
   - データの前処理と選択が結果に大きく影響

2. 実験設計の重要性
   - パラメータ変更は比較実験とセットで行う
   - ad-hocな調整は避け、系統的な実験を心がける

3. 計算リソースの考慮
   - アルゴリズムによって実行時間とメモリ使用量が大きく異なる
   - スケーラビリティを考慮した実験設計が必要
   - クラスタサイズの分布: クラスタの均一性を評価

4. 実験結果
   a) シルエット係数
      - HDBSCAN: 0.115（密度ベースのクラスタリングがより効果的）
      - k-means: 0.024（クラスタ間の分離が不十分）

   b) クラスタの特徴
      - HDBSCAN
        * 平均サイズ: 4.45（より小さく密度の高いクラスタ）
        * サイズの範囲: 3-6（より均一なサイズ分布）
        * 平均密度: 1.183（より高密度）
        * 平均距離: 0.851（より近接したデータポイント）
      - k-means
        * 平均サイズ: 12.55（より大きく疎なクラスタ）
        * サイズの範囲: 4-29（不均一なサイズ分布）
        * 平均密度: 0.999（より低密度）
        * 平均距離: 1.003（より離れたデータポイント）

5. 考察
   - HDBSCANは密度ベースのアプローチにより、より自然なクラスタリングを実現
   - 小さく密度の高いクラスタは、類似した意見のグループを表している可能性が高い
   - k-meansは事前に指定したクラスタ数に合わせて強制的に分割するため、
     自然な意見のグループ分けができていない可能性がある

### 今後の研究の方向性
1. クラスタリング手法の比較実験
   - k-meansでkを大きく取った場合の効果検証（k=50,100,200）
   - UMAPによる次元削減の効果検証
     * 2次元化してからクラスタリング
     * クラスタリングしてからUMAP可視化
   - クラスタの解説文生成と質の評価

2. パラメータの影響調査
   - オリジナルのHDBSCANパラメータを基準とした比較
   - 各パラメータの影響を体系的に評価

### 環境構築手順
1. リポジトリのセットアップ
   ```bash
   git clone https://github.com/nishio/broadlistening-research.git
   cd broadlistening-research
   ```

2. データセットの取得
   - anno-broadelistening/scatter/pipeline/outputs/aipubcom/から以下のファイルを取得:
     * embeddings.pkl (261MB): コメントのベクトル表現
     * args.csv: コメントのメタデータ
   - dataset/aipubcom/ディレクトリに配置

3. 必要なPythonパッケージのインストール
   ```bash
   pip install pandas numpy scikit-learn hdbscan umap-learn matplotlib
   ```

### 追試方法
1. オリジナルのパラメータでの実験
   ```python
   python experiments/original_params.py
   ```

2. 比較実験の実行
   ```python
   python experiments/clustering_framework.py
   ```

3. 結果の確認
   - experiment_comparison.png: 可視化結果
   - experiment_results.csv: 詳細な評価指標

### 研究をしてみての学び
1. パラメータの重要性
   - パラメータの変更は必ず比較実験を通じて評価する必要がある
   - アドホックな調整は避け、客観的な指標に基づいて判断する

2. 実験の再現性
   - すべての設定と結果を詳細に記録することの重要性
   - 環境構築手順の明確な文書化の必要性

3. 評価指標の選択
   - シルエット係数だけでなく、複数の指標を用いた総合的な評価の重要性
   - クラスタの質を定量的に評価する方法の検討

### 感想
1. クラスタリングの難しさ
   - パラメータ調整の影響が大きい
   - ノイズの扱いが重要な課題

2. 今後の課題
   - より体系的な比較実験の必要性
   - クラスタの解説文生成による質的評価の可能性
   - 次元削減との組み合わせ効果の検証
